{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNRZWI4VOsq9Tvuskmn1tqp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mr-MaNia7/deep-learning/blob/main/DL_Lab_3_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "yh0CEHZznlYr"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Activation Function Definitions\n"
      ],
      "metadata": {
        "id": "nOhncZwbrDee"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "sDPu5JDihKwV"
      },
      "outputs": [],
      "source": [
        "def activation_relu(inputs):\n",
        "    return torch.maximum(torch.tensor(0, dtype=inputs.dtype), inputs)\n",
        "\n",
        "def activation_softmax(inputs):\n",
        "    exponents = torch.exp(inputs - torch.max(inputs))\n",
        "    return torch.exp(inputs - torch.max(inputs)) / torch.sum(exponents)\n",
        "\n",
        "def activation_sigmoid(inputs):\n",
        "    return 1 / (1 + torch.exp(-inputs))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unified Dense Layer\n"
      ],
      "metadata": {
        "id": "BJx6sSZlrAen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UnifiedDenseLayer:\n",
        "    def __init__(self, n_features, n_neurons):\n",
        "        self.weights = torch.rand((n_features, n_neurons))\n",
        "        self.biases = torch.zeros((1, n_neurons))\n",
        "\n",
        "    def forward(self, inputs, activation_function):\n",
        "        weighted_sum = torch.matmul(inputs, self.weights) + self.biases\n",
        "        self.output = activation_function(weighted_sum)"
      ],
      "metadata": {
        "id": "9LMevvyijrxR"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss: Categorical Cross Entropy\n"
      ],
      "metadata": {
        "id": "VLx__qBYq9ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def categorical_cross_entropy(y_pred, y_true):\n",
        "    clipped_predictions = torch.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "    log_likelihoods = -torch.sum(y_true * torch.log(clipped_predictions))\n",
        "    return log_likelihoods"
      ],
      "metadata": {
        "id": "j7XHvOGNpqDX"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section: Unified Training\n"
      ],
      "metadata": {
        "id": "3zvBpTEqq6te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_training(activation_function):\n",
        "    torch.manual_seed(7)\n",
        "    input_data = torch.rand((1, 4))\n",
        "\n",
        "    # 3 hidden layers\n",
        "    layer1 = UnifiedDenseLayer(4, 18)\n",
        "    layer2 = UnifiedDenseLayer(18, 18)\n",
        "    layer3 = UnifiedDenseLayer(18, 18)\n",
        "    # output layer\n",
        "    output_layer = UnifiedDenseLayer(18, 3)\n",
        "\n",
        "    # Forward pass\n",
        "    layer1.forward(input_data, activation_function)\n",
        "    layer2.forward(layer1.output, activation_function)\n",
        "    layer3.forward(layer2.output, activation_function)\n",
        "    output_layer.forward(layer3.output, activation_softmax)\n",
        "\n",
        "    target = torch.tensor([1,1,0])\n",
        "\n",
        "    # Computing loss\n",
        "    loss = categorical_cross_entropy(output_layer.output, target)\n",
        "    accuracy = target == torch.argmax(output_layer.output, axis=1)\n",
        "\n",
        "    print(f\"Using {activation_function} for hidden layers:\")\n",
        "    print(\"Final output:\", output_layer.output)\n",
        "    print(\"Categorical Cross-Entropy Loss:\", loss.item())"
      ],
      "metadata": {
        "id": "j72drdG_pq-Z"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section: Unified Training\n"
      ],
      "metadata": {
        "id": "D8Yo1UyWq3mk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_training(activation_function):\n",
        "    torch.manual_seed(7)\n",
        "    input_data = torch.rand((1, 4))\n",
        "\n",
        "    # 3 hidden layers\n",
        "    layer1 = UnifiedDenseLayer(4, 18)\n",
        "    layer2 = UnifiedDenseLayer(18, 18)\n",
        "    layer3 = UnifiedDenseLayer(18, 18)\n",
        "    # output layer\n",
        "    output_layer = UnifiedDenseLayer(18, 3)\n",
        "\n",
        "    # Forward pass\n",
        "    layer1.forward(input_data, activation_function)\n",
        "    layer2.forward(layer1.output, activation_function)\n",
        "    layer3.forward(layer2.output, activation_function)\n",
        "    output_layer.forward(layer3.output, activation_softmax)\n",
        "\n",
        "    target = torch.tensor([1,1,0])\n",
        "\n",
        "    # Computing loss\n",
        "    loss = categorical_cross_entropy(output_layer.output, target)\n",
        "    accuracy = target == torch.argmax(output_layer.output, axis=1)\n",
        "\n",
        "    print(f\"\\nUsing {activation_function.__name__} for activating hidden layers:\")\n",
        "    print(\"Final output:\", output_layer.output)\n",
        "    print(\"Categorical Cross-Entropy Loss:\", loss.item())\n",
        "    print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "V_zIdOTWqgS2"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Unified Trainings"
      ],
      "metadata": {
        "id": "VBmYNqfLqz7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_training(activation_relu)\n",
        "run_training(activation_sigmoid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJlzMIdRqjuj",
        "outputId": "39863afb-f3c1-400e-bf29-2647109cf38b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using activation_relu for activating hidden layers:\n",
            "Final output: tensor([[1.0000e+00, 6.5041e-34, 2.6831e-37]])\n",
            "Categorical Cross-Entropy Loss: 16.11809539794922\n",
            "Accuracy: tensor([False, False,  True])\n",
            "\n",
            "Using activation_sigmoid for activating hidden layers:\n",
            "Final output: tensor([[0.5770, 0.2014, 0.2216]])\n",
            "Categorical Cross-Entropy Loss: 2.1524696350097656\n",
            "Accuracy: tensor([False, False,  True])\n"
          ]
        }
      ]
    }
  ]
}